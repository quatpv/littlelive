{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ed37f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from src.pipeline.ageing_report import AgeingReportPipeline\n",
    "from src.utils.logger import setup_logging, get_logger\n",
    "from src.utils.spark_utils import create_spark_session, load_config, read_input_file\n",
    "from src.config.models import AppConfig\n",
    "from pyspark.sql.types import (\n",
    "    DateType,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    "    DoubleType,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd7c1d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "as_at_date = date(2025, 7, 7)\n",
    "env = \"prod\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b35ab7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_path = f\"config/config_{env}.yaml\"\n",
    "config_dict = load_config(config_path)\n",
    "config = AppConfig(**config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "969b56ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = setup_logging(level=config.logging.level, format_str=config.logging.format)\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb52d766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-18 22:53:31,424 - __main__ - INFO - Starting Ageing Report Pipeline for environment: prod\n",
      "2025-07-18 22:53:31,427 - __main__ - INFO - As-at date: 2025-07-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/18 22:53:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-18 22:53:38,423 - src.pipeline.data_validator - INFO - Starting comprehensive data validation...\n",
      "2025-07-18 22:53:38,425 - src.pipeline.data_validator - INFO - Validating invoices dataframe...\n",
      "2025-07-18 22:53:41,596 - src.pipeline.data_validator - INFO - invoices row count: 8\n",
      "2025-07-18 22:53:42,847 - src.pipeline.data_validator - INFO - invoices validation completed successfully\n",
      "2025-07-18 22:53:42,849 - src.pipeline.data_validator - INFO - Validating credit_notes dataframe...\n",
      "2025-07-18 22:53:43,018 - src.pipeline.data_validator - INFO - credit_notes row count: 8\n",
      "2025-07-18 22:53:43,893 - src.pipeline.data_validator - INFO - credit_notes validation completed successfully\n",
      "2025-07-18 22:53:43,895 - src.pipeline.data_validator - INFO - Validating payments dataframe...\n",
      "2025-07-18 22:53:44,005 - src.pipeline.data_validator - INFO - payments row count: 8\n",
      "2025-07-18 22:53:44,756 - src.pipeline.data_validator - INFO - payments validation completed successfully\n",
      "2025-07-18 22:53:44,757 - src.pipeline.data_validator - INFO - All input validations completed successfully\n",
      "2025-07-18 22:53:44,758 - src.pipeline.ageing_report - INFO - Registering temporary tables...\n",
      "2025-07-18 22:53:44,826 - src.pipeline.ageing_report - INFO - Temporary tables registered successfully\n",
      "2025-07-18 22:53:44,827 - src.pipeline.ageing_report - INFO - Unioning documents...\n",
      "2025-07-18 22:53:44,995 - src.pipeline.ageing_report - INFO - Documents union completed.\n",
      "2025-07-18 22:53:44,997 - src.pipeline.ageing_report - INFO - Calculating outstanding amounts\n",
      "2025-07-18 22:53:45,217 - src.pipeline.ageing_report - INFO - Outstanding amounts calculated.\n",
      "2025-07-18 22:53:45,219 - src.pipeline.ageing_report - INFO - Applying ageing buckets for as_at_date: 2025-07-07\n",
      "2025-07-18 22:53:45,338 - src.pipeline.ageing_report - INFO - Ageing buckets applied\n",
      "2025-07-18 22:53:45,339 - src.pipeline.data_validator - INFO - Starting data output validation...\n",
      "2025-07-18 22:53:45,340 - src.pipeline.data_validator - INFO - Validating ageing_report dataframe...\n",
      "2025-07-18 22:53:46,428 - src.pipeline.data_validator - INFO - ageing_report row count: 13\n",
      "2025-07-18 22:53:51,039 - src.pipeline.data_validator - INFO - ageing_report validation completed successfully\n",
      "2025-07-18 22:53:51,040 - src.pipeline.data_validator - INFO - All output validations completed successfully\n",
      "2025-07-18 22:53:51,042 - src.pipeline.ageing_report - INFO - Write ageing_report to file: data/prod/output/ageing_report\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Starting Ageing Report Pipeline for environment: {env}\")\n",
    "logger.info(f\"As-at date: {as_at_date}\")\n",
    "\n",
    "# Create Spark session\n",
    "spark = create_spark_session(config)\n",
    "\n",
    "# Initialize pipeline\n",
    "pipeline = AgeingReportPipeline(spark, config)\n",
    "\n",
    "# Run the pipeline\n",
    "pipeline.generate_ageing_report(as_at_date)\n",
    "\n",
    "ageing_report_schema = StructType(\n",
    "    [\n",
    "        StructField(\"centre_id\", StringType(), True),\n",
    "        StructField(\"class_id\", StringType(), True),\n",
    "        StructField(\"document_id\", StringType(), True),\n",
    "        StructField(\"document_date\", DateType(), True),\n",
    "        StructField(\"student_id\", StringType(), True),\n",
    "        StructField(\"day_30\", DoubleType(), True),\n",
    "        StructField(\"day_60\", DoubleType(), True),\n",
    "        StructField(\"day_90\", DoubleType(), True),\n",
    "        StructField(\"day_120\", DoubleType(), True),\n",
    "        StructField(\"day_150\", DoubleType(), True),\n",
    "        StructField(\"day_180\", DoubleType(), True),\n",
    "        StructField(\"day_180_and_above\", DoubleType(), True),\n",
    "        StructField(\"document_type\", StringType(), False),\n",
    "        StructField(\"as_at_date\", DateType(), False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ageing_report = read_input_file(\n",
    "    spark=spark,\n",
    "    file_format=config.pipeline.outputs.format,\n",
    "    file_path=f\"{config.pipeline.outputs.path}_{as_at_date.strftime('%Y-%m-%d')}.{config.pipeline.outputs.format}\",\n",
    "    schema=ageing_report_schema,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4d82546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-----------+-------------+----------+------+------+------+-------+-------+-------+-----------------+-------------+----------+\n",
      "|centre_id|class_id|document_id|document_date|student_id|day_30|day_60|day_90|day_120|day_150|day_180|day_180_and_above|document_type|as_at_date|\n",
      "+---------+--------+-----------+-------------+----------+------+------+------+-------+-------+-------+-----------------+-------------+----------+\n",
      "|0_02     |cls_01  |cr_007     |2025-05-05   |stu_007   |0.0   |0.0   |110.0 |0.0    |0.0    |0.0    |0.0              |credit_note  |2025-07-07|\n",
      "|0_02     |cls_03  |cr_003     |2024-12-01   |stu_003   |0.0   |0.0   |0.0   |0.0    |0.0    |0.0    |200.0            |credit_note  |2025-07-07|\n",
      "|0_03     |c15_03  |cr_006     |2025-02-28   |stu_006   |0.0   |0.0   |0.0   |0.0    |40.0   |0.0    |0.0              |credit_note  |2025-07-07|\n",
      "|c_01     |cls_01  |cr_001     |2025-05-15   |5tu_001   |0.0   |100.0 |0.0   |0.0    |0.0    |0.0    |0.0              |credit_note  |2025-07-07|\n",
      "|c_01     |cls_01  |cr_004     |2025-01-20   |5tu_004   |0.0   |0.0   |0.0   |0.0    |0.0    |120.0  |0.0              |credit_note  |2025-07-07|\n",
      "|c_01     |cls_01  |inv_001    |2025-05-01   |stu_001   |0.0   |0.0   |150.0 |0.0    |0.0    |0.0    |0.0              |invoice      |2025-07-07|\n",
      "|c_01     |cls_01  |inv_005    |2025-02-01   |stu_005   |0.0   |0.0   |0.0   |0.0    |0.0    |100.0  |0.0              |invoice      |2025-07-07|\n",
      "|c_01     |cls_02  |inv_008    |2025-06-20   |stu_008   |100.0 |0.0   |0.0   |0.0    |0.0    |0.0    |0.0              |invoice      |2025-07-07|\n",
      "|c_02     |cls_01  |inv_003    |2025-01-01   |stu_003   |0.0   |0.0   |0.0   |0.0    |0.0    |0.0    |500.0            |invoice      |2025-07-07|\n",
      "|c_02     |els_02  |er_002     |2025-03-10   |5tu_002   |0.0   |0.0   |0.0   |50.0   |0.0    |0.0    |0.0              |credit_note  |2025-07-07|\n",
      "|c_03     |cls_01  |inv_007    |2025-03-20   |stu_007   |0.0   |0.0   |0.0   |300.0  |0.0    |0.0    |0.0              |invoice      |2025-07-07|\n",
      "|c_03     |cls_02  |cr_005     |2025-06-01   |5tu_005   |0.0   |200.0 |0.0   |0.0    |0.0    |0.0    |0.0              |credit_note  |2025-07-07|\n",
      "|c_03     |cls_03  |inv_004    |2024-12-15   |stu_004   |0.0   |0.0   |0.0   |0.0    |0.0    |0.0    |300.0            |invoice      |2025-07-07|\n",
      "+---------+--------+-----------+-------------+----------+------+------+------+-------+-------+-------+-----------------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ageing_report.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
